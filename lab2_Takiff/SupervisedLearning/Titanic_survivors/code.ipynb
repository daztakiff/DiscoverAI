{
    "metadata": {
        "kernelspec": {
            "name": "python3",
            "display_name": "Python 3 (ipykernel)",
            "language": "python"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2,
    "cells": [
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# **Titanic Survivors with Decision Trees**"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "The code below is taken from Manav Sehgal's submission on [kaggle.com](https://www.kaggle.com/startupsci/titanic-data-science-solutions/notebook).\n",
                "\n",
                "You are encouraged to go to the link above and check the full code. In this lab, you will do the necessary steps to explore the data and prepare it for sklearn algorithms."
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "**About the data set**"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "On April 15, 1912, during her maiden voyage, the Titanic sank after colliding with an iceberg, killing 1502 out of 2224 passengers and crew. Translated 32% survival rate.\n",
                "One of the reasons that the shipwreck led to such loss of life was that there were not enough lifeboats for the passengers and crew.\n",
                "\n",
                "Although there was some element of luck involved in surviving the sinking, some groups of people were more likely to survive than others, such as women, children, and the upper-class."
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "**Import libraries**"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 212,
            "metadata": {},
            "outputs": [],
            "source": [
                "# data analysis and wrangling\n",
                "import numpy as np # linear algebra\n",
                "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
                "#import random as rnd\n",
                "\n",
                "# visualization\n",
                "import seaborn as sns\n",
                "import matplotlib.pyplot as plt\n",
                "%matplotlib inline"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Acquire data"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 213,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Acquire the training data set\n",
                "train_df = pd.read_csv('SupervisedLearning/Titanic_survivors/train.csv')\n",
                "\n",
                "# Acquire the testing data set \n",
                "test_df = pd.read_csv('SupervisedLearning/Titanic_survivors/test.csv')\n",
                "\n",
                "# Combine these datasets to run certain operations on both datasets together.\n",
                "combine = [train_df, test_df]"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Inspect data"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 214,
            "metadata": {},
            "outputs": [],
            "source": [
                "#TODO: Write code to display the features available in train_df\n",
                "#Hint: Use columns.values\n",
                ""
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 0,
            "metadata": {},
            "outputs": [],
            "source": [
                "#TODO: Write code to inspect the first five rows of train_df\n",
                ""
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "**Which features are categorical?**\n",
                "\n",
                "These values classify the samples into sets of similar samples. Within categorical features are the values nominal, ordinal, ratio, or interval based? Among other things this helps us select the appropriate plots for visualization.\n",
                "\n",
                "In the text box below, list all the categorical features.\n",
                ""
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "**answer here:**"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "**Which features are numerical?** \n",
                "\n",
                "These values change from sample to sample. Within numerical features are the values discrete, continuous, or timeseries based? Among other things this helps us select the appropriate plots for visualization.\n",
                "\n",
                "In the text box below, list all the continuous and discrete features."
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "**answer here:**"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "**Which features are mixed data types?**\n",
                "\n",
                "Numerical, alphanumeric data within same feature. These are candidates for correcting goal.\n",
                "\n",
                "* Ticket is a mix of numeric and alphanumeric data types. Cabin is alphanumeric.\n",
                "\n",
                ""
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "**Which features may contain errors or typos?**\n",
                "\n",
                "This is harder to review for a large dataset, however reviewing a few samples from a smaller dataset may just tell us outright, which features may require correcting.\n",
                "\n",
                "* Name feature may contain errors or typos as there are several ways used to describe a name including titles, round brackets, and quotes used for alternative or short names."
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "**Which features contain blank, null or empty values?**\n",
                "\n",
                "Write code below to find the answer."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 215,
            "metadata": {},
            "outputs": [],
            "source": [
                "#TODO: Write code to get the information on train_df  \n",
                ""
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 216,
            "metadata": {},
            "outputs": [],
            "source": [
                "#TODO: Write code to get the information on test_df \n",
                ""
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "**answer here:** "
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Clean data"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "**1. Correcting**\n",
                "\n",
                "This is a good starting goal to execute. By dropping features we are dealing with fewer data points. Speeds up our notebook and eases the analysis.\n",
                "\n",
                "Note that where applicable we perform operations on both training and testing datasets together to stay consistent.\n",
                "\n",
                "* Ticket feature may be dropped from our analysis as it contains high ratio of duplicates (22%) and there may not be a correlation between Ticket and survival.\n",
                "* Cabin feature may be dropped as it is highly incomplete or contains many null values both in training and test dataset.\n",
                "* PassengerId may be dropped from training dataset as it does not contribute to survival.\n",
                "* Name feature is relatively non-standard, may not contribute directly to survival, so maybe dropped. This will be dropped later, after creating some new features out of it."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 217,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Display the new structure of all data frames before dropping two columns\n",
                "print(\"Before\", train_df.shape, test_df.shape, combine[0].shape, \n",
                "       combine[1].shape)\n",
                "\n",
                "# Drop Ticket and Cabin columns from train_df\n",
                "train_df = train_df.drop(['Ticket', 'Cabin'], axis=1)\n",
                "\n",
                "#TODO: Write code to drop Ticket and Cabin columns from test_df\n",
                "\n",
                "# Reset the combine data frame with the new values in both datasets\n",
                "combine = [train_df, test_df]\n",
                "\n",
                "#TODO: Write code to display the new structure of all data frames after dropping two columns\n",
                ""
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 218,
            "metadata": {},
            "outputs": [],
            "source": [
                "#TODO: Write code to drop the PassengerId feature in the training dataset.\n",
                "\n",
                "\n",
                "# Reset the combine data frame\n",
                "combine = [train_df, test_df]\n",
                "\n",
                "#TODO: Write code to display the shape of train_df and test_df\n",
                ""
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "**2. Creating**\n",
                "\n",
                "We want to analyze if Name feature can be engineered to extract titles and test correlation between titles and survival, before dropping the Name feature.\n",
                "\n",
                "In the following code we extract Title feature using regular expressions. The RegEx pattern (\\w+\\.) matches the first word which ends with a dot character within Name feature. The expand=False flag returns a DataFrame.\n",
                "\n",
                "Most titles band Age groups accurately.\n",
                "Survival among Title Age bands varies slightly.\n",
                "Certain titles mostly survived (Mme, Lady, Sir) or did not (Don, Rev, Jonkheer).\n",
                "\n",
                "We decide to retain the new Title feature for model training.\n",
                "\n",
                "The crosstab() function is used to compute a simple cross tabulation of two (or more) factors."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 219,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Loop through each item in the combined data set and extract\n",
                "# titles from the Name column\n",
                "for dataset in combine:\n",
                "    dataset['Title'] = dataset.Name.str.extract(' ([A-Za-z]+)\\.', expand=False)\n",
                "\n",
                "pd.crosstab(train_df['Title'], train_df['Sex'])"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 220,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Replace titles with a more \n",
                "# common name or classify them as Rare.\n",
                "for dataset in combine:\n",
                "    dataset['Title'] = dataset['Title'].replace('Mlle', 'Miss')\n",
                "    dataset['Title'] = dataset['Title'].replace('Ms', 'Miss')\n",
                "    dataset['Title'] = dataset['Title'].replace('Mme', 'Mrs')\n",
                "    #TODO: Write code to replace the remaining titles with 'Rare'.\n",
                "    #Note: In the replace function, you can group multiple items using brackets.\n",
                "    # Example: replace(['Rev','Major'], 'Rare')\n",
                "    \n",
                "    \n",
                "train_df[['Title', 'Survived']].groupby(['Title'], as_index=False).mean()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 221,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Convert the categorical titles to ordinal.\n",
                "title_mapping = {\"Mr\": 1, \"Miss\": 2, \"Mrs\": 3, \"Master\": 4, \"Rare\": 5}\n",
                "for dataset in combine:\n",
                "    dataset['Title'] = dataset['Title'].map(title_mapping)\n",
                "    dataset['Title'] = dataset['Title'].fillna(0)\n",
                "\n",
                "#TODO: Write code to inspect the first five rows of train_df\n",
                ""
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 222,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Safely drop the Name feature from training and testing datasets. \n",
                "train_df = train_df.drop(['Name'], axis=1)\n",
                "test_df = test_df.drop(['Name'], axis=1)\n",
                "\n",
                "# Recreate the combine data frame with the new values of train_df and test_df\n",
                "combine = [train_df, test_df]\n",
                "\n",
                "#TODO: Write code to inspect the new shape of both data frames\n",
                ""
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "**3. Converting**\n",
                "\n",
                "convert features which contain strings to numerical values. This is required by most model algorithms. Doing so will also help us in achieving the feature completing goal.\n",
                "\n",
                ""
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 223,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Convert Sex feature to a new feature called Gender where \n",
                "# female=1 and male=0.\n",
                "for dataset in combine:\n",
                "    dataset['Sex'] = dataset['Sex'].map( {'female': 1, 'male': 0} ).astype(int)\n",
                "\n",
                "#TODO: Write code to inspect the first five rows of train_df\n",
                ""
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "**4. Completing**"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "**4.a.** Complete Age feature for null values, as it is definitely correlated to survival.\n",
                "* Guess missing values using other correlated features. \n",
                "* We note correlation among Age, Gender, and Pclass. \n",
                "* Guess Age values using median values for Age across sets of Pclass and Gender feature combinations. \n",
                "* So, median Age for Pclass=1 and Gender=0, Pclass=1 and Gender=1, etc"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 224,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Prepare an empty array to contain guessed Age values based on \n",
                "# Pclass x Gender combinations.\n",
                "guess_ages = np.zeros((2,3))\n",
                "guess_ages"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 225,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Iterate over Sex (0 or 1) and Pclass (1, 2, 3) to calculate guessed\n",
                "# values of Age for the six combinations.\n",
                "for dataset in combine:\n",
                "    for i in range(0, 2):\n",
                "        for j in range(0, 3):\n",
                "            guess_df = dataset[(dataset['Sex'] == i) \u0026 \\\n",
                "                                  (dataset['Pclass'] == j+1)]['Age'].dropna()\n",
                "\n",
                "            age_guess = guess_df.median()\n",
                "\n",
                "            # Convert random age float to nearest .5 age\n",
                "            guess_ages[i,j] = int( age_guess/0.5 + 0.5 ) * 0.5\n",
                "            \n",
                "    for i in range(0, 2):\n",
                "        for j in range(0, 3):\n",
                "            dataset.loc[ (dataset.Age.isnull()) \u0026 (dataset.Sex == i) \u0026 (dataset.Pclass == j+1),\\\n",
                "                    'Age'] = guess_ages[i,j]\n",
                "\n",
                "    dataset['Age'] = dataset['Age'].astype(int)\n",
                "\n",
                "#TODO: Write code to inspect the first five rows of train_df\n",
                ""
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 226,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Create Age bands and determine correlations with Survived.\n",
                "train_df['AgeBand'] = pd.cut(train_df['Age'], 5)\n",
                "train_df[['AgeBand', 'Survived']].groupby(['AgeBand'], \n",
                "as_index=False).mean().sort_values(by='AgeBand', ascending=True)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 227,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Replace Age with ordinals based on these bands.\n",
                "for dataset in combine:    \n",
                "    dataset.loc[ dataset['Age'] \u003c= 16, 'Age'] = 0\n",
                "    dataset.loc[(dataset['Age'] \u003e 16) \u0026 (dataset['Age'] \u003c= 32), 'Age'] = 1\n",
                "    dataset.loc[(dataset['Age'] \u003e 32) \u0026 (dataset['Age'] \u003c= 48), 'Age'] = 2\n",
                "    dataset.loc[(dataset['Age'] \u003e 48) \u0026 (dataset['Age'] \u003c= 64), 'Age'] = 3\n",
                "    dataset.loc[ dataset['Age'] \u003e 64, 'Age']\n",
                "    \n",
                "#TODO: Write code to inspect the first five rows of train_df\n",
                ""
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 228,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Now it's safe to remove the AgeBand feature from the training data\n",
                "train_df = train_df.drop(['AgeBand'], axis=1)\n",
                "combine = [train_df, test_df]\n",
                "\n",
                "#TODO: Write code to inspect the first five rows of train_df\n",
                ""
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "**4.b.** Complete the Embarked feature as it may also correlate with survival or another important feature."
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Embarked feature takes S, Q, C values based on port of embarkation. Our training dataset has two missing values. We simply fill these with the most common occurance."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 229,
            "metadata": {},
            "outputs": [],
            "source": [
                "freq_port = train_df.Embarked.dropna().mode()[0]\n",
                "\n",
                "for dataset in combine:\n",
                "    dataset['Embarked'] = dataset['Embarked'].fillna(freq_port)\n",
                "    \n",
                "train_df[['Embarked', 'Survived']].groupby(['Embarked'], as_index=False).mean().sort_values(by='Survived', ascending=False)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 230,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Convert the EmbarkedFill feature by creating a new numeric Port feature.\n",
                "for dataset in combine:\n",
                "    dataset['Embarked'] = dataset['Embarked'].map( {'S': 0, 'C': 1, 'Q': 2} ).astype(int)\n",
                "\n",
                "#TODO: Write code to inspect the first five rows of train_df\n",
                ""
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 231,
            "metadata": {},
            "outputs": [],
            "source": [
                "#TODO: Write code to inspect the first five rows of test_df\n",
                ""
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "**Creating**\n",
                "\n",
                "There are more features that can be created to facilitate the analysis of this data set:\n",
                "\n",
                "* We may want to create a new feature called Family based on Parch and SibSp to get total count of family members on board.\n",
                "* We may want to engineer the Name feature to extract Title as a new feature.\n",
                "* We may want to create new feature for Age bands. This turns a continous numerical feature into an ordinal categorical feature.\n",
                "* We may also want to create a Fare range feature if it helps our analysis.\n",
                ""
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 232,
            "metadata": {},
            "outputs": [],
            "source": [
                "# create a new feature for FamilySize which combines Parch and SibSp. \n",
                "# This will enable us to drop Parch and SibSp from our datasets.\n",
                "for dataset in combine:\n",
                "    dataset['FamilySize'] = dataset['SibSp'] + dataset['Parch'] + 1\n",
                "\n",
                "train_df[['FamilySize', 'Survived']].groupby(['FamilySize'], \n",
                "as_index=False).mean().sort_values(by='Survived', ascending=False)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 233,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Create the IsAlone feature\n",
                "for dataset in combine:\n",
                "    dataset['IsAlone'] = 0\n",
                "    dataset.loc[dataset['FamilySize'] == 1, 'IsAlone'] = 1\n",
                "\n",
                "train_df[['IsAlone', 'Survived']].groupby(['IsAlone'], as_index=False).mean()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 234,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Drop Parch, SibSp, and FamilySize features in favor of IsAlone.\n",
                "train_df = train_df.drop(['Parch', 'SibSp', 'FamilySize'], axis=1)\n",
                "test_df = test_df.drop(['Parch', 'SibSp', 'FamilySize'], axis=1)\n",
                "combine = [train_df, test_df]\n",
                "\n",
                "#TODO: Write code to inspect the first five rows of train_df\n",
                ""
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 235,
            "metadata": {},
            "outputs": [],
            "source": [
                "# We can also create an artificial feature combining Pclass and Age.\n",
                "for dataset in combine:\n",
                "    dataset['Age*Class'] = dataset.Age * dataset.Pclass\n",
                "\n",
                "train_df.loc[:, ['Age*Class', 'Age', 'Pclass']].head(10)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 236,
            "metadata": {},
            "outputs": [],
            "source": [
                "test_df['Fare'].fillna(test_df['Fare'].dropna().median(), inplace=True)\n",
                "#TODO: Write code to inspect the first five rows of train_df\n",
                ""
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 237,
            "metadata": {},
            "outputs": [],
            "source": [
                "# We can not create FareBand.\n",
                "train_df['FareBand'] = pd.qcut(train_df['Fare'], 4)\n",
                "train_df[['FareBand', 'Survived']].groupby(['FareBand'], as_index=False).mean().sort_values(by='FareBand', ascending=True)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 238,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Convert the Fare feature to ordinal values based on the FareBand.\n",
                "for dataset in combine:\n",
                "    dataset.loc[ dataset['Fare'] \u003c= 7.91, 'Fare'] = 0\n",
                "    dataset.loc[(dataset['Fare'] \u003e 7.91) \u0026 (dataset['Fare'] \u003c= 14.454), 'Fare'] = 1\n",
                "    dataset.loc[(dataset['Fare'] \u003e 14.454) \u0026 (dataset['Fare'] \u003c= 31), 'Fare']   = 2\n",
                "    dataset.loc[ dataset['Fare'] \u003e 31, 'Fare'] = 3\n",
                "    dataset['Fare'] = dataset['Fare'].astype(int)\n",
                "\n",
                "train_df = train_df.drop(['FareBand'], axis=1)\n",
                "combine = [train_df, test_df]\n",
                "    \n",
                "#TODO: Write code to inspect the first five rows of train_df\n",
                ""
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 239,
            "metadata": {},
            "outputs": [],
            "source": [
                "#TODO: Write code to inspect the first five rows of test_df\n",
                ""
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Earn Your Wings"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Use a decision tree classifier on the cleaned data set to predict 'Survived' for the given data. Report the accuracy score. Add comments in your code to explain each step that you take in your implementation."
            ]
        }
    ]
}
