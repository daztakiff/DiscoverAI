{
    "metadata": {
        "kernelspec": {
            "name": "python3",
            "display_name": "Python 3 (ipykernel)",
            "language": "python"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2,
    "cells": [
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# **Entropy-based assessment of clusters**"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "This code is taken from an introduction to unsupervised learning with **K-Means Clustering** following [this tutorial](https://youtu.be/EItlUEPCIzM).\n",
                "\n",
                "The elbow method implemented in lab 1 and 2 is a great test of figuring out the optimal value of clusters to create.\n",
                "\n",
                "Entropy-based tests, like the **homogeneity score** can be used in supervised clustering problems. \n",
                "The homogeneity score estimates how many of the predicted clusters contain only members of a single class. The higher the core is the better the clustering.\n",
                "\n",
                "Homogeneity is computed based on the conditional entropy H(y_true|y_pred), which measures the uncertainty in the determining the right class after having the clustered dataset:\n",
                "\n",
                "![alt text](/home/homogeneity_score.png)\n",
                "\n",
                " To explore the homogeneity test, we will assume that we know the ground truth clustering (y_true) for the given data set, and compare it to the predicted clusters for different values of K."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Import packages\n",
                "from sklearn.cluster import KMeans\n",
                "import pandas as pd\n",
                "from sklearn.preprocessing import MinMaxScaler\n",
                "from matplotlib import pyplot as plt\n",
                "from sklearn.metrics import homogeneity_score\n",
                "%matplotlib inline"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "**1. Read in the data**"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/html": "\u003cdiv\u003e\n\u003cstyle scoped\u003e\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n\u003c/style\u003e\n\u003ctable border=\"1\" class=\"dataframe\"\u003e\n  \u003cthead\u003e\n    \u003ctr style=\"text-align: right;\"\u003e\n      \u003cth\u003e\u003c/th\u003e\n      \u003cth\u003eName\u003c/th\u003e\n      \u003cth\u003eAge\u003c/th\u003e\n      \u003cth\u003eIncome($)\u003c/th\u003e\n    \u003c/tr\u003e\n  \u003c/thead\u003e\n  \u003ctbody\u003e\n    \u003ctr\u003e\n      \u003cth\u003e0\u003c/th\u003e\n      \u003ctd\u003eRob\u003c/td\u003e\n      \u003ctd\u003e27\u003c/td\u003e\n      \u003ctd\u003e70000\u003c/td\u003e\n    \u003c/tr\u003e\n    \u003ctr\u003e\n      \u003cth\u003e1\u003c/th\u003e\n      \u003ctd\u003eMichael\u003c/td\u003e\n      \u003ctd\u003e29\u003c/td\u003e\n      \u003ctd\u003e90000\u003c/td\u003e\n    \u003c/tr\u003e\n    \u003ctr\u003e\n      \u003cth\u003e2\u003c/th\u003e\n      \u003ctd\u003eMohan\u003c/td\u003e\n      \u003ctd\u003e29\u003c/td\u003e\n      \u003ctd\u003e61000\u003c/td\u003e\n    \u003c/tr\u003e\n    \u003ctr\u003e\n      \u003cth\u003e3\u003c/th\u003e\n      \u003ctd\u003eIsmail\u003c/td\u003e\n      \u003ctd\u003e28\u003c/td\u003e\n      \u003ctd\u003e60000\u003c/td\u003e\n    \u003c/tr\u003e\n    \u003ctr\u003e\n      \u003cth\u003e4\u003c/th\u003e\n      \u003ctd\u003eKory\u003c/td\u003e\n      \u003ctd\u003e42\u003c/td\u003e\n      \u003ctd\u003e150000\u003c/td\u003e\n    \u003c/tr\u003e\n  \u003c/tbody\u003e\n\u003c/table\u003e\n\u003c/div\u003e",
                        "text/plain": "      Name  Age  Income($)\n0      Rob   27      70000\n1  Michael   29      90000\n2    Mohan   29      61000\n3   Ismail   28      60000\n4     Kory   42     150000"
                    },
                    "execution_count": 3,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "df = pd.read_csv('UnsupervisedLearning/clustering_test.csv')\n",
                "\n",
                "#TODO: Write code to inspect the first five rows of the data frame\n",
                "df.head()"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "**2. Use the MinMax scaler to fit the data**"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "metadata": {},
            "outputs": [],
            "source": [
                "scaler = MinMaxScaler()\n",
                "\n",
                "scaler.fit(df[['Income($)']])\n",
                "df['Income($)'] = scaler.transform(df[['Income($)']])\n",
                "\n",
                "scaler.fit(df[['Age']])\n",
                "df['Age'] = scaler.transform(df[['Age']])\n",
                "\n",
                "plt.scatter(df.Age,df['Income($)'])"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "**3.A. Elbow method: compute the sum of squared error for different values of k**"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "metadata": {},
            "outputs": [],
            "source": [
                "sse = []\n",
                "k_rng = range(1,10)\n",
                "for k in k_rng:\n",
                "    km = KMeans(n_clusters=k)\n",
                "    km.fit(df[['Age','Income($)']])\n",
                "    sse.append(km.inertia_)"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "**Plot SSE for different values of K to find the optimal K**"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "metadata": {},
            "outputs": [],
            "source": [
                "plt.xlabel('K')\n",
                "plt.ylabel('Sum of squared error')\n",
                "plt.plot(k_rng,sse)"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "**3.B. Use the homogeneity score on different values of K**"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 6,
            "metadata": {},
            "outputs": [],
            "source": [
                "y_true = [0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2]\n",
                "homogeneityscore = []\n",
                "completenessScore = []\n",
                "k_rng = range(1,10)\n",
                "for k in k_rng:\n",
                "    km = KMeans(n_clusters=k)\n",
                "    y_predicted = km.fit_predict(df[['Age','Income($)']])\n",
                "    homogeneityscore.append(homogeneity_score(y_true, y_predicted))\n",
                ""
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "**Plot homogeneity score for different values of K to find the optimal K**"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 7,
            "metadata": {},
            "outputs": [],
            "source": [
                "plt.xlabel('K')\n",
                "plt.ylabel('homogeneity score')\n",
                "plt.plot(k_rng, homogeneityscore)"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "**4. Use KMeans to create 3 clusters**"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 8,
            "metadata": {},
            "outputs": [],
            "source": [
                "km = KMeans(n_clusters=3)\n",
                "y_predicted = km.fit_predict(df[['Age','Income($)']])\n",
                "df['cluster']=y_predicted\n",
                "df1 = df[df.cluster==0]\n",
                "df2 = df[df.cluster==1]\n",
                "df3 = df[df.cluster==2]\n",
                "plt.scatter(df1.Age,df1['Income($)'],color='green')\n",
                "plt.scatter(df2.Age,df2['Income($)'],color='red')\n",
                "plt.scatter(df3.Age,df3['Income($)'],color='black')\n",
                "plt.scatter(km.cluster_centers_[:,0],km.cluster_centers_[:,1],color='purple',marker='*',label='centroid')\n",
                "plt.legend()"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "**5. Earn Your Wings: DO it yourself**\n",
                "\n",
                "Test this algorithm on your own data set. Note that this will require a ground truth for the clustering, as shown in step 3.B. "
            ]
        }
    ]
}
